{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUuKD4qe7Gxu",
        "outputId": "7233d52d-e080-47c0-e51d-7601274eaad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç LINKEDIN NAME DISCOVERY WITH COMPANY REGEX FILTERING\n",
            "=================================================================\n",
            "\n",
            "üéØ SEARCH CONFIGURATION:\n",
            "   People to find: 1\n",
            "   Company regex pattern: '.*Grant.*'\n",
            "   Additional filters: {'location': 'India'}\n",
            "üîç BRIGHT DATA LINKEDIN NAME DISCOVERY WITH COMPANY FILTERING\n",
            "Using OFFICIAL API endpoints for name-based search + regex filtering\n",
            "======================================================================\n",
            "Company filter pattern: '.*Grant.*'\n",
            "Case sensitive: False\n",
            "üîç Triggering LinkedIn name discovery for 1 people...\n",
            "   1. Chandreyee Mukherjee\n",
            "API URL: https://api.brightdata.com/datasets/v3/trigger\n",
            "Dataset ID: gd_l1viktl72bvl7bjuj0\n",
            "Search parameters: {'dataset_id': 'gd_l1viktl72bvl7bjuj0', 'include_errors': 'true', 'type': 'discover_new', 'discover_by': 'name', 'location': 'India'}\n",
            "Response status: 200\n",
            "‚úÖ Name discovery job triggered successfully!\n",
            "Snapshot ID: sd_mfxufg46106clnjf5z\n",
            "üéØ Discovery job started with snapshot ID: sd_mfxufg46106clnjf5z\n",
            "\n",
            "‚è≥ WAITING FOR DISCOVERY COMPLETION...\n",
            "‚è≥ Waiting for discovery job sd_mfxufg46106clnjf5z to complete...\n",
            "üí° Discovery jobs may take longer - timeout after 600 seconds\n",
            "Attempt 1: Status 202 (0s elapsed)\n",
            "‚è≥ Job still processing... (discovery can take several minutes)\n",
            "Attempt 2: Status 202 (20s elapsed)\n",
            "‚è≥ Job still processing... (discovery can take several minutes)\n",
            "Attempt 3: Status 202 (40s elapsed)\n",
            "‚è≥ Job still processing... (discovery can take several minutes)\n",
            "Attempt 4: Status 202 (60s elapsed)\n",
            "‚è≥ Job still processing... (discovery can take several minutes)\n",
            "Attempt 5: Status 200 (80s elapsed)\n",
            "‚úÖ Discovery job sd_mfxufg46106clnjf5z is ready!\n",
            "\n",
            "üì• DOWNLOADING RESULTS...\n",
            "üì° Downloading discovery results from snapshot: sd_mfxufg46106clnjf5z\n",
            "‚úÖ Successfully downloaded discovery data!\n",
            "‚úÖ Successfully discovered 37 profiles!\n",
            "\n",
            "üîç APPLYING COMPANY REGEX FILTERING...\n",
            "üîç Filtering profiles with company regex: '.*Grant.*'\n",
            "   Case sensitive: False\n",
            "   ‚úÖ Chandreyee Mukherjee - Matches: Current: Grant Thornton INDUS, Experience: Grant Thornton INDUS\n",
            "üìä Company filtering results:\n",
            "   Total profiles searched: 37\n",
            "   Profiles matching '.*Grant.*': 1\n",
            "üéØ Found 1 matching profiles, selecting best match...\n",
            "‚úÖ Selected best match: Chandreyee Mukherjee\n",
            "\n",
            "üìã COMPANY-FILTERED LINKEDIN PROFILES\n",
            "=================================================================\n",
            "Total matching profiles: 1\n",
            "\n",
            "üë§ PROFILE 1:\n",
            "   Name: Chandreyee Mukherjee\n",
            "   LinkedIn ID: chandreyee90\n",
            "   Location: Kolkata, West Bengal, India\n",
            "   üéØ Company Matches: Current: Grant Thornton INDUS, Experience: Grant Thornton INDUS\n",
            "   Current Company: Grant Thornton INDUS\n",
            "   Current Position: Assistant Manager | Performance Marketing (US)\n",
            "   Recent Experience:\n",
            "     1. Assistant Manager | Performance Marketing (US) at Grant Thornton INDUS (Jul 2025 - Present)\n",
            "     2. Deputy Manager | Digital Marketing ( Global) at ELGI EQUIPMENTS LIMITED (Sep 2021 - Jul 2025)\n",
            "   Profile URL: https://eg.linkedin.com/in/chandreyee90\n",
            "\n",
            "üíæ Filtered results saved to: linkedin_company_filtered_20250924_103159.json\n",
            "‚úÖ Discovery completed successfully with 1 matching profiles!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "from typing import Dict, List, Optional\n",
        "from datetime import datetime\n",
        "\n",
        "class BrightDataLinkedInNameScraper:\n",
        "    def __init__(self, api_token: str, dataset_id: str = \"gd_l1viktl72bvl7bjuj0\"):\n",
        "        \"\"\"\n",
        "        Initialize LinkedIn name-based scraper with Bright Data API\n",
        "\n",
        "        Args:\n",
        "            api_token: Your Bright Data API token\n",
        "            dataset_id: Your LinkedIn scraper dataset ID\n",
        "        \"\"\"\n",
        "        self.api_token = api_token\n",
        "        self.dataset_id = dataset_id\n",
        "        self.headers = {\n",
        "            \"Authorization\": f\"Bearer {api_token}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        self.base_url = \"https://api.brightdata.com/datasets/v3\"\n",
        "\n",
        "    def trigger_name_discovery(self, people: List[Dict[str, str]],\n",
        "                             additional_params: Optional[Dict] = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Trigger LinkedIn profile discovery using names\n",
        "\n",
        "        Args:\n",
        "            people: List of dictionaries with 'first_name' and 'last_name'\n",
        "            additional_params: Optional additional search parameters (company, location, etc.)\n",
        "\n",
        "        Returns:\n",
        "            API response with job details including snapshot_id\n",
        "        \"\"\"\n",
        "        # Validate input data\n",
        "        for person in people:\n",
        "            if 'first_name' not in person or 'last_name' not in person:\n",
        "                return {\"error\": \"Each person must have 'first_name' and 'last_name'\"}\n",
        "\n",
        "        api_url = f\"{self.base_url}/trigger\"\n",
        "        params = {\n",
        "            \"dataset_id\": self.dataset_id,\n",
        "            \"include_errors\": \"true\",\n",
        "            \"type\": \"discover_new\",\n",
        "            \"discover_by\": \"name\"\n",
        "        }\n",
        "\n",
        "        # Add any additional search parameters\n",
        "        if additional_params:\n",
        "            params.update(additional_params)\n",
        "\n",
        "        print(f\"üîç Triggering LinkedIn name discovery for {len(people)} people...\")\n",
        "        for i, person in enumerate(people, 1):\n",
        "            name_display = f\"{person['first_name']} {person['last_name']}\"\n",
        "            # Add company/location if provided in person data\n",
        "            if 'company' in person:\n",
        "                name_display += f\" (Company: {person['company']})\"\n",
        "            if 'location' in person:\n",
        "                name_display += f\" (Location: {person['location']})\"\n",
        "            print(f\"   {i}. {name_display}\")\n",
        "\n",
        "        print(f\"API URL: {api_url}\")\n",
        "        print(f\"Dataset ID: {self.dataset_id}\")\n",
        "        print(f\"Search parameters: {params}\")\n",
        "\n",
        "        try:\n",
        "            response = requests.post(api_url, headers=self.headers, json=people, params=params)\n",
        "\n",
        "            print(f\"Response status: {response.status_code}\")\n",
        "\n",
        "            if response.status_code in [200, 201, 202]:\n",
        "                result = response.json()\n",
        "                print(f\"‚úÖ Name discovery job triggered successfully!\")\n",
        "                print(f\"Snapshot ID: {result.get('snapshot_id')}\")\n",
        "                return result\n",
        "            else:\n",
        "                print(f\"‚ùå Request failed: {response.status_code}\")\n",
        "                print(f\"Response: {response.text}\")\n",
        "                return {\"error\": f\"HTTP {response.status_code}\", \"details\": response.text}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error triggering discovery: {e}\")\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "    def wait_for_completion(self, snapshot_id: str, max_wait: int = 600, check_interval: int = 20) -> bool:\n",
        "        \"\"\"\n",
        "        Wait for a name discovery job to complete\n",
        "        Name discovery typically takes longer than URL scraping\n",
        "\n",
        "        Args:\n",
        "            snapshot_id: The snapshot ID to wait for\n",
        "            max_wait: Maximum wait time in seconds (default 10 minutes)\n",
        "            check_interval: Check interval in seconds\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        print(f\"‚è≥ Waiting for discovery job {snapshot_id} to complete...\")\n",
        "        print(f\"üí° Discovery jobs may take longer - timeout after {max_wait} seconds\")\n",
        "\n",
        "        attempts = 0\n",
        "        while time.time() - start_time < max_wait:\n",
        "            attempts += 1\n",
        "\n",
        "            url = f\"{self.base_url}/snapshot/{snapshot_id}\"\n",
        "            params = {\"format\": \"json\"}\n",
        "\n",
        "            try:\n",
        "                response = requests.get(url, headers=self.headers, params=params)\n",
        "                elapsed = int(time.time() - start_time)\n",
        "\n",
        "                print(f\"Attempt {attempts}: Status {response.status_code} ({elapsed}s elapsed)\")\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    print(f\"‚úÖ Discovery job {snapshot_id} is ready!\")\n",
        "                    return True\n",
        "                elif response.status_code == 202:\n",
        "                    print(f\"‚è≥ Job still processing... (discovery can take several minutes)\")\n",
        "                elif response.status_code == 404:\n",
        "                    print(f\"‚è≥ Job not found yet, still initializing...\")\n",
        "                else:\n",
        "                    print(f\"‚ùå Unexpected status: {response.status_code}\")\n",
        "                    print(f\"Response: {response.text[:200]}...\")\n",
        "\n",
        "            except Exception as e:\n",
        "                elapsed = int(time.time() - start_time)\n",
        "                print(f\"‚è≥ Error checking job status ({elapsed}s elapsed): {e}\")\n",
        "\n",
        "            time.sleep(check_interval)\n",
        "\n",
        "        print(f\"‚è∞ Timeout reached after {max_wait} seconds\")\n",
        "        print(f\"üí° Job may still be running - you can check later with snapshot ID: {snapshot_id}\")\n",
        "        return False\n",
        "\n",
        "    def download_results(self, snapshot_id: str) -> Optional[List[Dict]]:\n",
        "        \"\"\"\n",
        "        Download discovered profile data from a completed job\n",
        "\n",
        "        Args:\n",
        "            snapshot_id: The snapshot ID to download from\n",
        "\n",
        "        Returns:\n",
        "            List of discovered profiles or None if failed\n",
        "        \"\"\"\n",
        "        url = f\"{self.base_url}/snapshot/{snapshot_id}\"\n",
        "        params = {\"format\": \"json\"}\n",
        "\n",
        "        print(f\"üì° Downloading discovery results from snapshot: {snapshot_id}\")\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, params=params)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                print(f\"‚úÖ Successfully downloaded discovery data!\")\n",
        "\n",
        "                # Handle different response formats\n",
        "                if isinstance(data, list):\n",
        "                    return data\n",
        "                elif isinstance(data, dict):\n",
        "                    if 'data' in data:\n",
        "                        return data['data']\n",
        "                    elif 'results' in data:\n",
        "                        return data['results']\n",
        "                    else:\n",
        "                        return [data]\n",
        "                return []\n",
        "\n",
        "            elif response.status_code == 202:\n",
        "                print(\"‚è≥ Snapshot still processing... try again later\")\n",
        "                return None\n",
        "            else:\n",
        "                print(f\"‚ùå Download failed: {response.status_code}\")\n",
        "                print(f\"Response: {response.text[:200]}...\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error downloading results: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_snapshots(self, status: str = \"ready\") -> Dict:\n",
        "        \"\"\"Get snapshots with specific status for troubleshooting\"\"\"\n",
        "        url = f\"{self.base_url}/snapshots\"\n",
        "        params = {\n",
        "            \"dataset_id\": self.dataset_id,\n",
        "            \"status\": status\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, params=params)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            else:\n",
        "                print(f\"Snapshots request failed: {response.status_code}\")\n",
        "                return {}\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting snapshots: {e}\")\n",
        "            return {}\n",
        "\n",
        "\n",
        "def select_best_profile_match(profiles: List[Dict], criteria: str = \"comprehensive\") -> Dict:\n",
        "    \"\"\"\n",
        "    Select the single best profile match from filtered results\n",
        "\n",
        "    Args:\n",
        "        profiles: List of profiles that already match the company filter\n",
        "        criteria: Selection criteria - \"comprehensive\", \"current_company\", \"most_recent\", \"highest_quality\"\n",
        "\n",
        "    Returns:\n",
        "        Single best matching profile\n",
        "    \"\"\"\n",
        "    if not profiles:\n",
        "        return {}\n",
        "\n",
        "    if len(profiles) == 1:\n",
        "        return profiles[0]\n",
        "\n",
        "    print(f\"   Selection criteria: {criteria}\")\n",
        "\n",
        "    if criteria == \"comprehensive\":\n",
        "        # Score based on multiple factors\n",
        "        scored_profiles = []\n",
        "\n",
        "        for profile in profiles:\n",
        "            score = 0\n",
        "            score_details = []\n",
        "\n",
        "            # Current company match (highest priority)\n",
        "            current_company = profile.get('current_company', {})\n",
        "            current_company_name = \"\"\n",
        "            if isinstance(current_company, dict):\n",
        "                current_company_name = current_company.get('name', '')\n",
        "            else:\n",
        "                current_company_name = profile.get('current_company_name', '')\n",
        "\n",
        "            company_matches = profile.get('_company_matches', [])\n",
        "            has_current_match = any('Current:' in match for match in company_matches)\n",
        "\n",
        "            if has_current_match:\n",
        "                score += 50  # High priority for current company match\n",
        "                score_details.append(\"Current company match (+50)\")\n",
        "\n",
        "            # Experience quality\n",
        "            experience = profile.get('experience', [])\n",
        "            if isinstance(experience, list) and len(experience) > 0:\n",
        "                score += len(experience) * 2\n",
        "                score_details.append(f\"Experience entries (+{len(experience) * 2})\")\n",
        "\n",
        "            # Profile completeness\n",
        "            if profile.get('about') and len(profile.get('about', '')) > 100:\n",
        "                score += 10\n",
        "                score_details.append(\"Detailed about section (+10)\")\n",
        "\n",
        "            # Connection count (indication of active profile)\n",
        "            connections = profile.get('connections', '0')\n",
        "            if str(connections).isdigit() and int(connections) > 100:\n",
        "                score += 15\n",
        "                score_details.append(\"High connections (+15)\")\n",
        "\n",
        "            # Followers count\n",
        "            followers = profile.get('followers', '0')\n",
        "            if str(followers).isdigit() and int(followers) > 500:\n",
        "                score += 10\n",
        "                score_details.append(\"High followers (+10)\")\n",
        "\n",
        "            # Location match (if specified in search)\n",
        "            # This would need additional logic based on search params\n",
        "\n",
        "            profile['_selection_score'] = score\n",
        "            profile['_score_details'] = score_details\n",
        "            scored_profiles.append((profile, score))\n",
        "\n",
        "        # Sort by score (highest first)\n",
        "        scored_profiles.sort(key=lambda x: x[1], reverse=True)\n",
        "        best_profile = scored_profiles[0][0]\n",
        "\n",
        "        print(f\"   Best match score: {best_profile['_selection_score']}\")\n",
        "        print(f\"   Score breakdown: {', '.join(best_profile['_score_details'])}\")\n",
        "\n",
        "        return best_profile\n",
        "\n",
        "    elif criteria == \"current_company\":\n",
        "        # Prioritize profiles with current company match\n",
        "        current_company_matches = []\n",
        "        for profile in profiles:\n",
        "            company_matches = profile.get('_company_matches', [])\n",
        "            if any('Current:' in match for match in company_matches):\n",
        "                current_company_matches.append(profile)\n",
        "\n",
        "        if current_company_matches:\n",
        "            return current_company_matches[0]  # Return first current company match\n",
        "        else:\n",
        "            return profiles[0]  # Fallback to first profile\n",
        "\n",
        "    elif criteria == \"most_recent\":\n",
        "        # Select profile with most recent experience at matching company\n",
        "        # This would require parsing dates - simplified version returns first\n",
        "        return profiles[0]\n",
        "\n",
        "    elif criteria == \"highest_quality\":\n",
        "        # Use existing quality scoring\n",
        "        quality_profiles = filter_quality_profiles(profiles, min_quality_score=1)\n",
        "        if quality_profiles:\n",
        "            return quality_profiles[0]  # Already sorted by quality\n",
        "        else:\n",
        "            return profiles[0]\n",
        "\n",
        "    return profiles[0]  # Default fallback\n",
        "\n",
        "\n",
        "def filter_profiles_by_company_regex(profiles: List[Dict], company_pattern: str,\n",
        "                                   case_sensitive: bool = False) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Filter profiles to only include those where the company pattern matches\n",
        "    current company or any past experience company names\n",
        "\n",
        "    Args:\n",
        "        profiles: List of discovered profiles\n",
        "        company_pattern: Regex pattern to match company names (e.g., \"Grant.*\" or \"Grant\")\n",
        "        case_sensitive: Whether the regex match should be case sensitive\n",
        "\n",
        "    Returns:\n",
        "        Filtered list of profiles matching the company pattern\n",
        "    \"\"\"\n",
        "    if not profiles or not company_pattern:\n",
        "        return profiles\n",
        "\n",
        "    # Compile regex pattern\n",
        "    flags = 0 if case_sensitive else re.IGNORECASE\n",
        "    try:\n",
        "        pattern = re.compile(company_pattern, flags)\n",
        "    except re.error as e:\n",
        "        print(f\"‚ùå Invalid regex pattern '{company_pattern}': {e}\")\n",
        "        return []\n",
        "\n",
        "    matched_profiles = []\n",
        "\n",
        "    print(f\"üîç Filtering profiles with company regex: '{company_pattern}'\")\n",
        "    print(f\"   Case sensitive: {case_sensitive}\")\n",
        "\n",
        "    for profile in profiles:\n",
        "        profile_matched = False\n",
        "        match_details = []\n",
        "\n",
        "        # Check current company\n",
        "        current_company = profile.get('current_company', {})\n",
        "        if isinstance(current_company, dict):\n",
        "            current_company_name = current_company.get('name', '')\n",
        "        else:\n",
        "            # Sometimes current_company might be a string\n",
        "            current_company_name = str(current_company) if current_company else ''\n",
        "\n",
        "        # Also check current_company_name field (alternative field name)\n",
        "        if not current_company_name:\n",
        "            current_company_name = profile.get('current_company_name', '')\n",
        "\n",
        "        if current_company_name and pattern.search(current_company_name):\n",
        "            profile_matched = True\n",
        "            match_details.append(f\"Current: {current_company_name}\")\n",
        "\n",
        "        # Check experience companies\n",
        "        experience = profile.get('experience', [])\n",
        "        if isinstance(experience, list):\n",
        "            for exp in experience:\n",
        "                if isinstance(exp, dict):\n",
        "                    exp_company = exp.get('company', '')\n",
        "                    if exp_company and pattern.search(exp_company):\n",
        "                        profile_matched = True\n",
        "                        match_details.append(f\"Experience: {exp_company}\")\n",
        "\n",
        "        # If profile matched, add it with match info\n",
        "        if profile_matched:\n",
        "            profile['_company_matches'] = match_details\n",
        "            matched_profiles.append(profile)\n",
        "            name = profile.get('name', 'Unknown')\n",
        "            print(f\"   ‚úÖ {name} - Matches: {', '.join(match_details)}\")\n",
        "\n",
        "    print(f\"üìä Company filtering results:\")\n",
        "    print(f\"   Total profiles searched: {len(profiles)}\")\n",
        "    print(f\"   Profiles matching '{company_pattern}': {len(matched_profiles)}\")\n",
        "\n",
        "    return matched_profiles\n",
        "\n",
        "\n",
        "def discover_linkedin_profiles_by_names_with_company_filter(\n",
        "    api_token: str,\n",
        "    dataset_id: str,\n",
        "    people: List[Dict[str, str]],\n",
        "    company_regex_pattern: str,\n",
        "    additional_params: Optional[Dict] = None,\n",
        "    case_sensitive: bool = False,\n",
        "    select_best_only: bool = False\n",
        ") -> Optional[List[Dict]]:\n",
        "    \"\"\"\n",
        "    Complete LinkedIn profile discovery workflow using names with regex company filtering\n",
        "\n",
        "    Args:\n",
        "        api_token: Your Bright Data API token\n",
        "        dataset_id: Your dataset ID\n",
        "        people: List of dictionaries with 'first_name' and 'last_name'\n",
        "        company_regex_pattern: Regex pattern to match company names (e.g., \"Grant.*\" or \"(?i)grant\")\n",
        "        additional_params: Optional global search parameters\n",
        "        case_sensitive: Whether company name matching should be case sensitive\n",
        "\n",
        "    Returns:\n",
        "        List of filtered profile data matching company pattern or None if failed\n",
        "    \"\"\"\n",
        "    scraper = BrightDataLinkedInNameScraper(api_token, dataset_id)\n",
        "\n",
        "    print(\"üîç BRIGHT DATA LINKEDIN NAME DISCOVERY WITH COMPANY FILTERING\")\n",
        "    print(\"Using OFFICIAL API endpoints for name-based search + regex filtering\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Company filter pattern: '{company_regex_pattern}'\")\n",
        "    print(f\"Case sensitive: {case_sensitive}\")\n",
        "\n",
        "    # Trigger discovery (remove company filter from API params to get broader results)\n",
        "    api_params = additional_params.copy() if additional_params else {}\n",
        "    if 'company' in api_params:\n",
        "        removed_company = api_params.pop('company')\n",
        "        print(f\"üìù Removed API company filter '{removed_company}' - will use regex instead\")\n",
        "\n",
        "    trigger_result = scraper.trigger_name_discovery(people, api_params)\n",
        "\n",
        "    if trigger_result.get(\"error\"):\n",
        "        print(\"‚ùå Failed to trigger discovery job\")\n",
        "        print(f\"Error details: {trigger_result}\")\n",
        "        return None\n",
        "\n",
        "    snapshot_id = trigger_result.get(\"snapshot_id\")\n",
        "    if not snapshot_id:\n",
        "        print(\"‚ùå No snapshot ID received from API\")\n",
        "        return None\n",
        "\n",
        "    print(f\"üéØ Discovery job started with snapshot ID: {snapshot_id}\")\n",
        "\n",
        "    # Wait for completion\n",
        "    print(f\"\\n‚è≥ WAITING FOR DISCOVERY COMPLETION...\")\n",
        "    job_completed = scraper.wait_for_completion(snapshot_id)\n",
        "\n",
        "    if job_completed:\n",
        "        # Download results\n",
        "        print(f\"\\nüì• DOWNLOADING RESULTS...\")\n",
        "        all_results = scraper.download_results(snapshot_id)\n",
        "\n",
        "        if all_results:\n",
        "            print(f\"‚úÖ Successfully discovered {len(all_results)} profiles!\")\n",
        "\n",
        "            # Apply company regex filtering\n",
        "            print(f\"\\nüîç APPLYING COMPANY REGEX FILTERING...\")\n",
        "            filtered_results = filter_profiles_by_company_regex(\n",
        "                all_results,\n",
        "                company_regex_pattern,\n",
        "                case_sensitive\n",
        "            )\n",
        "\n",
        "            if filtered_results:\n",
        "                if select_best_only:\n",
        "                    print(f\"üéØ Found {len(filtered_results)} matching profiles, selecting best match...\")\n",
        "                    best_match = select_best_profile_match(filtered_results)\n",
        "                    print(f\"‚úÖ Selected best match: {best_match.get('name', 'Unknown')}\")\n",
        "                    return [best_match]  # Return as list for consistency\n",
        "                else:\n",
        "                    print(f\"üéØ Final results: {len(filtered_results)} profiles match company pattern!\")\n",
        "                    return filtered_results\n",
        "            else:\n",
        "                print(f\"‚ùå No profiles found matching company pattern '{company_regex_pattern}'\")\n",
        "                print(f\"üí° Consider:\")\n",
        "                print(f\"   - Using a broader regex pattern (e.g., 'Grant.*' instead of 'Grant')\")\n",
        "                print(f\"   - Making the search case-insensitive\")\n",
        "                print(f\"   - Checking if the company appears in different formats\")\n",
        "                return None\n",
        "        else:\n",
        "            print(\"‚ùå No profiles discovered or download failed\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"‚ùå Discovery job did not complete within timeout\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def display_company_filtered_profiles(profiles: List[Dict], max_display: int = 10):\n",
        "    \"\"\"Display company-filtered profiles with match details\"\"\"\n",
        "    if not profiles:\n",
        "        print(\"No profiles to display\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüìã COMPANY-FILTERED LINKEDIN PROFILES\")\n",
        "    print(\"=\" * 65)\n",
        "    print(f\"Total matching profiles: {len(profiles)}\")\n",
        "\n",
        "    for i, profile in enumerate(profiles[:max_display], 1):\n",
        "        print(f\"\\nüë§ PROFILE {i}:\")\n",
        "        print(f\"   Name: {profile.get('name', 'N/A')}\")\n",
        "        print(f\"   LinkedIn ID: {profile.get('id', profile.get('linkedin_id', 'N/A'))}\")\n",
        "        print(f\"   Location: {profile.get('city', 'N/A')}\")\n",
        "\n",
        "        # Show company matches\n",
        "        company_matches = profile.get('_company_matches', [])\n",
        "        print(f\"   üéØ Company Matches: {', '.join(company_matches)}\")\n",
        "\n",
        "        # Current company details\n",
        "        current_company = profile.get('current_company', {})\n",
        "        if isinstance(current_company, dict):\n",
        "            company_name = current_company.get('name', 'N/A')\n",
        "            company_title = current_company.get('title', 'N/A')\n",
        "        else:\n",
        "            company_name = profile.get('current_company_name', 'N/A')\n",
        "            company_title = profile.get('position', 'N/A')\n",
        "\n",
        "        print(f\"   Current Company: {company_name}\")\n",
        "        print(f\"   Current Position: {company_title}\")\n",
        "\n",
        "        # Show relevant experience\n",
        "        experience = profile.get('experience', [])\n",
        "        if isinstance(experience, list) and len(experience) > 0:\n",
        "            print(f\"   Recent Experience:\")\n",
        "            for j, exp in enumerate(experience[:2], 1):  # Show first 2 experiences\n",
        "                if isinstance(exp, dict):\n",
        "                    exp_title = exp.get('title', 'N/A')\n",
        "                    exp_company = exp.get('company', 'N/A')\n",
        "                    exp_dates = f\"{exp.get('start_date', '')} - {exp.get('end_date', 'Present')}\"\n",
        "                    print(f\"     {j}. {exp_title} at {exp_company} ({exp_dates})\")\n",
        "\n",
        "        # Profile URL\n",
        "        profile_url = profile.get('url', profile.get('linkedin_url', 'N/A'))\n",
        "        print(f\"   Profile URL: {profile_url}\")\n",
        "\n",
        "    if len(profiles) > max_display:\n",
        "        print(f\"\\n... and {len(profiles) - max_display} more matching profiles\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function demonstrating LinkedIn name discovery with company regex filtering\"\"\"\n",
        "\n",
        "    # Configuration with your API token\n",
        "    API_TOKEN = \"\"\n",
        "    DATASET_ID = \"gd_l1viktl72bvl7bjuj0\"\n",
        "\n",
        "    print(\"üîç LINKEDIN NAME DISCOVERY WITH COMPANY REGEX FILTERING\")\n",
        "    print(\"=\" * 65)\n",
        "\n",
        "    # Example: Search for people by name\n",
        "    people_to_discover = [\n",
        "        {\"first_name\": \"Chandreyee\", \"last_name\": \"Mukherjee\"}\n",
        "    ]\n",
        "\n",
        "    # Company regex pattern - modify this to match your needs\n",
        "    # Examples:\n",
        "    # \"Grant\" - exact match\n",
        "    # \"Grant.*\" - starts with Grant\n",
        "    # \".*Grant.*\" - contains Grant anywhere\n",
        "    # \"(?i)grant\" - case insensitive exact match\n",
        "    # \"Grant|grant\" - exact match Grant or grant\n",
        "    COMPANY_REGEX_PATTERN = \".*Grant.*\"  # This will match any company containing \"Grant\"\n",
        "\n",
        "    # Optional: Add other search parameters (but remove company filter - we'll use regex instead)\n",
        "    additional_search_params = {\n",
        "        \"location\": \"India\",\n",
        "        # Don't include \"company\" here - we'll filter with regex after getting results\n",
        "    }\n",
        "\n",
        "    print(f\"\\nüéØ SEARCH CONFIGURATION:\")\n",
        "    print(f\"   People to find: {len(people_to_discover)}\")\n",
        "    print(f\"   Company regex pattern: '{COMPANY_REGEX_PATTERN}'\")\n",
        "    print(f\"   Additional filters: {additional_search_params}\")\n",
        "\n",
        "    # Run the discovery with company filtering\n",
        "    results = discover_linkedin_profiles_by_names_with_company_filter(\n",
        "        API_TOKEN,\n",
        "        DATASET_ID,\n",
        "        people_to_discover,\n",
        "        COMPANY_REGEX_PATTERN,\n",
        "        additional_search_params,\n",
        "        case_sensitive=False,  # Set to True if you want case-sensitive matching\n",
        "        select_best_only=True  # Set to True to get only the best match\n",
        "    )\n",
        "\n",
        "    if results:\n",
        "        # Display filtered profiles\n",
        "        display_company_filtered_profiles(results)\n",
        "\n",
        "        # Save results\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"linkedin_company_filtered_{timestamp}.json\"\n",
        "\n",
        "        metadata = {\n",
        "            \"discovery_timestamp\": datetime.now().isoformat(),\n",
        "            \"company_regex_pattern\": COMPANY_REGEX_PATTERN,\n",
        "            \"total_matching_profiles\": len(results),\n",
        "            \"search_parameters\": {\n",
        "                \"people_searched\": people_to_discover,\n",
        "                \"additional_params\": additional_search_params\n",
        "            }\n",
        "        }\n",
        "\n",
        "        data_package = {\n",
        "            \"metadata\": metadata,\n",
        "            \"filtered_profiles\": results\n",
        "        }\n",
        "\n",
        "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(data_package, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"\\nüíæ Filtered results saved to: {filename}\")\n",
        "        print(f\"‚úÖ Discovery completed successfully with {len(results)} matching profiles!\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\n‚ùå No profiles found matching the company pattern\")\n",
        "        print(\"\\nüîß TROUBLESHOOTING TIPS:\")\n",
        "        print(\"   1. Try a broader regex pattern (e.g., '.*Grant.*')\")\n",
        "        print(\"   2. Make the search case-insensitive\")\n",
        "        print(\"   3. Check if company names appear in different formats\")\n",
        "        print(\"   4. Remove location filters to get more initial results\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
